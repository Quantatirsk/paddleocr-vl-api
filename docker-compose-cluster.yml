services:
  # Nginx 负载均衡器
  nginx:
    image: nginx:alpine
    ports:
      - "8780:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - vllm-server-1
      - vllm-server-2
      - vllm-server-3
      - vllm-server-4
      - vllm-server-5
      - vllm-server-6
    restart: unless-stopped

  # GPU 0
  vllm-server-1:
    image: ccr-2vdh3abv-pub.cnc.bj.baidubce.com/paddlepaddle/paddleocr-genai-vllm-server:latest-nvidia-gpu-offline
    environment:
      - NVIDIA_VISIBLE_DEVICES=0
      - VLM_BACKEND=vllm
    runtime: nvidia
    volumes:
      - ./models:/root/.paddlex/official_models
    command: paddleocr genai_server --model_name PaddleOCR-VL-1.5-0.9B --host 0.0.0.0 --port 8000 --backend vllm
    restart: unless-stopped

  vllm-server-2:
    image: ccr-2vdh3abv-pub.cnc.bj.baidubce.com/paddlepaddle/paddleocr-genai-vllm-server:latest-nvidia-gpu-offline
    environment:
      - NVIDIA_VISIBLE_DEVICES=0
      - VLM_BACKEND=vllm
    runtime: nvidia
    volumes:
      - ./models:/root/.paddlex/official_models
    command: paddleocr genai_server --model_name PaddleOCR-VL-1.5-0.9B --host 0.0.0.0 --port 8000 --backend vllm
    restart: unless-stopped

  # GPU 1
  vllm-server-3:
    image: ccr-2vdh3abv-pub.cnc.bj.baidubce.com/paddlepaddle/paddleocr-genai-vllm-server:latest-nvidia-gpu-offline
    environment:
      - NVIDIA_VISIBLE_DEVICES=1
      - VLM_BACKEND=vllm
    runtime: nvidia
    volumes:
      - ./models:/root/.paddlex/official_models
    command: paddleocr genai_server --model_name PaddleOCR-VL-1.5-0.9B --host 0.0.0.0 --port 8000 --backend vllm
    restart: unless-stopped

  vllm-server-4:
    image: ccr-2vdh3abv-pub.cnc.bj.baidubce.com/paddlepaddle/paddleocr-genai-vllm-server:latest-nvidia-gpu-offline
    environment:
      - NVIDIA_VISIBLE_DEVICES=1
      - VLM_BACKEND=vllm
    runtime: nvidia
    volumes:
      - ./models:/root/.paddlex/official_models
    command: paddleocr genai_server --model_name PaddleOCR-VL-1.5-0.9B --host 0.0.0.0 --port 8000 --backend vllm
    restart: unless-stopped

  # GPU 2
  vllm-server-5:
    image: ccr-2vdh3abv-pub.cnc.bj.baidubce.com/paddlepaddle/paddleocr-genai-vllm-server:latest-nvidia-gpu-offline
    environment:
      - NVIDIA_VISIBLE_DEVICES=2
      - VLM_BACKEND=vllm
    runtime: nvidia
    volumes:
      - ./models:/root/.paddlex/official_models
    command: paddleocr genai_server --model_name PaddleOCR-VL-1.5-0.9B --host 0.0.0.0 --port 8000 --backend vllm
    restart: unless-stopped

  vllm-server-6:
    image: ccr-2vdh3abv-pub.cnc.bj.baidubce.com/paddlepaddle/paddleocr-genai-vllm-server:latest-nvidia-gpu-offline
    environment:
      - NVIDIA_VISIBLE_DEVICES=2
      - VLM_BACKEND=vllm
    runtime: nvidia
    volumes:
      - ./models:/root/.paddlex/official_models
    command: paddleocr genai_server --model_name PaddleOCR-VL-1.5-0.9B --host 0.0.0.0 --port 8000 --backend vllm
    restart: unless-stopped

  ocr-api:
    image: quantatrisk/paddleocr-api:latest
    ports:
      - "8781:8080"
    environment:
      - VLLM_SERVER_URL=http://nginx:80/v1
      - MAX_WORKERS=${MAX_WORKERS:-4}
      - THREAD_WORKERS=${THREAD_WORKERS:-10}
    volumes:
      - ./models:/root/.paddlex/official_models
    depends_on:
      - nginx
    restart: unless-stopped
